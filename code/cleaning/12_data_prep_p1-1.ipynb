{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Data Prep Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Unless you try to do something beyond what you have already mastered, you will never grow.â€ ~ \n",
    "Ronald E. Osborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mississippi river](https://i0.wp.com/www.firstinarchitecture.co.uk/wp-content/uploads/2018/04/Image-014.jpg?w=656&ssl=1)  \n",
    "**Source:** Harold Norman Fisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Outline\n",
    "\n",
    "1. Project Definition\n",
    "2. Data Gathering\n",
    "3. Summary\n",
    "4. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![solving](pictures/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data detectives, we want to make sure we have at least a loosly define outline of what our projects involving data might look like. In particular, we want to be extra careful with those involving large amounts of data since errors can, at the very least, be very time consuming and, at worst, expensive.\n",
    "\n",
    "For our task, we are currently sick and tired of COVID and we want to start planning our next vacation. More specifically, we would love to scratch some countries off our bucket list, but, since this can be quite costly, we want to start by figuring out more information about the options we have, given the top 2, 4, 5, etc., countries we want to visit. In essence, we want to find the best deal possible given a set of criteria that we will polish as we explore the data further.\n",
    "\n",
    "> **Project/Goal:** To find the best place to stay at for our next vacation in terms of costs, venue, and things to do around it, given our top 3 destinations for 2021.\n",
    "\n",
    "> **Today we will cover:** The grueling process of collecting and cleaning the data and then move on to Analysing the heck out of it.\n",
    "\n",
    "Since hotels are expensive, we thought we would give Airbnb a try. We found this awesome website called [Inside Airbnb](http://insideairbnb.com/about.html) that has gathered a large amount of Airbnb data, and has made it publicly available for anyone to use and analyse to their heart's content. We will take advantage of this but, since we don't want to click and download every single file, one at a time, we will write some code to get us the data we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gathering Data](pictures/9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using data scraped from a scraping tool called, [Inside Airbnb](http://insideairbnb.com/index.html). Yes, we will be scraping a bit of data from the scraper itsef. More specifically, we will be taking the skeleton (an html version of the website), downloading it, and then extracting all of the links that will help us get the data from it.\n",
    "\n",
    "We will start by importing the following packages to help us get the data we need.\n",
    "\n",
    "- [`os`](https://docs.python.org/3/library/os.html) --> allows to interact with, and mofify, files within our operating system.\n",
    "- [`pandas`](https://pandas.pydata.org/) --> swiss army knife for data analysis in Python.\n",
    "- [`numpy`](https://numpy.org/) --> core module behind the swiss army knife, and overall, excellent tool for numerical computing in Python.\n",
    "- [`requests`](https://requests.readthedocs.io/en/master/) --> HTTP library for Python.\n",
    "- [`bs4`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) --> web scraping tool.\n",
    "- [`wget`](https://pypi.org/project/wget/) --> useful tool to download data with using Python.\n",
    "- [`glob`](https://docs.python.org/3.8/library/glob.html) --> excellent tool for finding and returning multiple files in your operating system using pattern matching (i.e. regex).\n",
    "- [`urllib`](https://docs.python.org/3.8/library/urllib.html) --> \"urllib is a powerful, user-friendly HTTP client for Python\" ~ [urllib](https://docs.python.org/3.8/library/urllib.html)\n",
    "- [`dask`](https://dask.org/) --> high performance computing module written in Python.\n",
    "\n",
    "Along the way, we will create different functions to help us avoid writing the same lines of code multiple times, and we will create multiple directories for our files to keep them neatly organised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rick\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: wget in c:\\users\\rick\\anaconda3\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rick\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# in case you don't have the following 2 packages, make sure you run this cell\n",
    "!pip install beautifulsoup4 wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import wget\n",
    "import numpy as np\n",
    "import dask\n",
    "from glob import glob\n",
    "import urllib\n",
    "\n",
    "# pandas by default only shows a few columns, we want them all!\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be creating several directories, the first thing we will do is to assign a path to the directory where all of our data will go into and come out from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data'\n",
    "\n",
    "# uncomment this one if you are using windows instead of a mac or linux\n",
    "# path = '..\\data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create a function that takes in an existing path as a starting point and many additional directory names that we might need/want to create along the way. In addition, our function will check whether the directory we are trying to create already exists, if not it will create one for each argument we pass into our function, then combine all arguments into one directory and return such directory.\n",
    "\n",
    "You might have already seen the `*args` parameter often used inside a function in Python. What this does is that it gives us the ability to provide multiple arguments to a function without explicitely adding them to the construction of the function. It helps us save space and time while working. In addition, some of our functions will depend on this one function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_or_add(old_path, *args):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will help us check whether one or more directories exists, and\n",
    "    if they don't exist, it will create, combine, and return a new directory.\n",
    "    \"\"\"\n",
    "        \n",
    "    if not os.path.exists(os.path.join(old_path, *args)):\n",
    "        os.makedirs(os.path.join(old_path, *args))\n",
    "\n",
    "    return os.path.join(old_path, *args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Python's `requests` library to send a request to __Inside Airbnb__, then use our path creation function to add this HTML file to a directory called, `raw_files`, and then save the HTML skeleton file as text using a context manager construct. We will call our file `insideairbnb.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Sends a GET request.\n",
       "\n",
       ":param url: URL for the new :class:`Request` object.\n",
       ":param params: (optional) Dictionary, list of tuples or bytes to send\n",
       "    in the query string for the :class:`Request`.\n",
       ":param \\*\\*kwargs: Optional arguments that ``request`` takes.\n",
       ":return: :class:`Response <Response>` object\n",
       ":rtype: requests.Response\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\rick\\anaconda3\\lib\\site-packages\\requests\\api.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "requests.get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data\\\\raw_files'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_4_source = check_or_add(path, 'raw_files')\n",
    "path_4_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_data = requests.get('http://insideairbnb.com/get-the-data.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path_4_source, 'insideairbnb.html'), 'w', encoding='utf-8') as html:\n",
    "    html.write(web_data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will combine the path to our new file with the name of such file to a variable called `html_doc`. We will then read it back into the session, and parse the document using `BeautifulSoup`. We will assign our parsed file to a variable called `soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data\\\\raw_files\\\\insideairbnb.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_doc = os.path.join(path_4_source, 'insideairbnb.html')\n",
    "html_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(html_doc, 'r', encoding='utf-8') as file: \n",
    "    soup = BeautifulSoup(file, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` will allow us to extract the links we need without much hassle. While we could figure out a way to get the exact links we need with a regular expression or a similar approach, we will extract all links at this stage by parsing the html file and taking out the links we need using pandas. For this, we will use a Python list comprehension and extract every hyperlink reference inside our parsed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index.html',\n",
       " 'about.html',\n",
       " 'behind.html',\n",
       " 'get-the-data.html',\n",
       " 'https://twitter.com/share',\n",
       " 'about.html#disclaimers',\n",
       " 'http://creativecommons.org/publicdomain/zero/1.0/',\n",
       " 'amsterdam/',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/data/listings.csv.gz',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/data/calendar.csv.gz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_links = [link.get('href') for link in soup.find_all('a')]\n",
    "list_of_links[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 21269 links. Wow!\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(list_of_links)} links. Wow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files we need are those that end with `listings.csv.gz` and, to extract them, (or filter out the ones we don't want), we can take advantage many string methods available in the pandas library.\n",
    "\n",
    "We will now convert our list into a pandas Series and assign it to a variable called `our_list`. You can think of this pandas Series as a 1 dimensional array with a visible, and very flexible, index. You can select elements from a pandas Series using its index in the same way you would do it with regular lists in Python, and you can also use diverse methods such as `.head()` and `.tail()` to examine the first or last 5 elements of an array, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a pandas Series\n",
    "pd.Series([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    hello\n",
       "1    SciPy\n",
       "2    Japan\n",
       "3     2020\n",
       "Name: say_hi, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is another pandas Series but this one has a name\n",
    "pd.Series(['hello', 'SciPy', 'Japan', '2020'], name='say_hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Japan'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select an index\n",
    "pd.Series(['hello', 'SciPy', 'Japan', '2020'], name='say_hi')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: lots_of_numbers, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_series = pd.Series(range(100), name='lots_of_numbers')\n",
    "toy_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas Series' have a very useful functionality inherited from NumPy that allows us to filter its elements by a specific condition. This is often referred to as masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "95     True\n",
       "96     True\n",
       "97     True\n",
       "98     True\n",
       "99     True\n",
       "Name: lots_of_numbers, Length: 100, dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition1 = (toy_series > 30)\n",
    "condition1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31    31\n",
       "32    32\n",
       "33    33\n",
       "34    34\n",
       "35    35\n",
       "      ..\n",
       "95    95\n",
       "96    96\n",
       "97    97\n",
       "98    98\n",
       "99    99\n",
       "Name: lots_of_numbers, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_series[condition1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine multiple operations with `&` and `|` which stand for `and` and `or`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "      ...  \n",
       "95    False\n",
       "96    False\n",
       "97    False\n",
       "98    False\n",
       "99    False\n",
       "Name: lots_of_numbers, Length: 100, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition2 = (toy_series < 60)\n",
    "condition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31    31\n",
       "32    32\n",
       "33    33\n",
       "34    34\n",
       "35    35\n",
       "36    36\n",
       "37    37\n",
       "38    38\n",
       "39    39\n",
       "40    40\n",
       "41    41\n",
       "42    42\n",
       "43    43\n",
       "44    44\n",
       "45    45\n",
       "46    46\n",
       "47    47\n",
       "48    48\n",
       "49    49\n",
       "50    50\n",
       "51    51\n",
       "52    52\n",
       "53    53\n",
       "54    54\n",
       "55    55\n",
       "56    56\n",
       "57    57\n",
       "58    58\n",
       "59    59\n",
       "Name: lots_of_numbers, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_series[(condition1) & (condition2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masks don't need to be passed in as variables but it certainly makes our code a bit cleaner and less error prone (this a completely unbiased opinion of course ðŸ˜Ž)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "      ..\n",
       "95    95\n",
       "96    96\n",
       "97    97\n",
       "98    98\n",
       "99    99\n",
       "Name: lots_of_numbers, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_series[(toy_series > 60) | (toy_series < 30)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we now a bit more about what a pandas Series is, let's continue working with the links from Inside Airbnb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index.html',\n",
       " 'about.html',\n",
       " 'behind.html',\n",
       " 'get-the-data.html',\n",
       " 'https://twitter.com/share',\n",
       " 'about.html#disclaimers',\n",
       " 'http://creativecommons.org/publicdomain/zero/1.0/',\n",
       " 'amsterdam/',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/data/listings.csv.gz',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/data/calendar.csv.gz',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/data/reviews.csv.gz',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/visualisations/listings.csv',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/visualisations/reviews.csv',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/visualisations/neighbourhoods.csv',\n",
       " 'http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2020-10-09/visualisations/neighbourhoods.geojson']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_links[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           index.html\n",
       "1                                           about.html\n",
       "2                                          behind.html\n",
       "3                                    get-the-data.html\n",
       "4                            https://twitter.com/share\n",
       "5                               about.html#disclaimers\n",
       "6    http://creativecommons.org/publicdomain/zero/1.0/\n",
       "7                                           amsterdam/\n",
       "8    http://data.insideairbnb.com/the-netherlands/n...\n",
       "9    http://data.insideairbnb.com/the-netherlands/n...\n",
       "Name: links, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_list = pd.Series(list_of_links, name='links')\n",
    "our_list.head(10) # let's examine the first five rows of our new pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check and see if we have any missing values before applying our string method to our pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_list.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a few missing values in our array, we will first get rid of them using pandas `.dopna()` method. We will then grab the listings links and filter out those links we don't want with a mask that tells pandas to grab only those files that end with `listings.csv.gz`. We will also reset the index just because it is nice to have values that start from 0 and go all the way to the end of our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mour_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Return a new Series with missing values removed.\n",
       "\n",
       "See the :ref:`User Guide <missing_data>` for more on which values are\n",
       "considered missing, and how to work with missing data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "axis : {0 or 'index'}, default 0\n",
       "    There is only one axis to drop values from.\n",
       "inplace : bool, default False\n",
       "    If True, do operation inplace and return None.\n",
       "how : str, optional\n",
       "    Not in use. Kept for compatibility.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series\n",
       "    Series with NA entries dropped from it.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Series.isna: Indicate missing values.\n",
       "Series.notna : Indicate existing (non-missing) values.\n",
       "Series.fillna : Replace missing values.\n",
       "DataFrame.dropna : Drop rows or columns which contain NA values.\n",
       "Index.dropna : Drop missing indices.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> ser = pd.Series([1., 2., np.nan])\n",
       ">>> ser\n",
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "dtype: float64\n",
       "\n",
       "Drop NA values from a Series.\n",
       "\n",
       ">>> ser.dropna()\n",
       "0    1.0\n",
       "1    2.0\n",
       "dtype: float64\n",
       "\n",
       "Keep the Series with valid entries in the same variable.\n",
       "\n",
       ">>> ser.dropna(inplace=True)\n",
       ">>> ser\n",
       "0    1.0\n",
       "1    2.0\n",
       "dtype: float64\n",
       "\n",
       "Empty strings are not considered NA values. ``None`` is considered an\n",
       "NA value.\n",
       "\n",
       ">>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n",
       ">>> ser\n",
       "0       NaN\n",
       "1         2\n",
       "2       NaT\n",
       "3\n",
       "4      None\n",
       "5    I stay\n",
       "dtype: object\n",
       ">>> ser.dropna()\n",
       "1         2\n",
       "3\n",
       "5    I stay\n",
       "dtype: object\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\rick\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "our_list.dropna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_list.dropna(inplace=True) # drop NaN's and keep the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "7    False\n",
       "8     True\n",
       "9    False\n",
       "Name: links, dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = our_list.str.endswith('/listings.csv.gz') # let's find the listings we need (index 8 is the first link that ends with listings.csv.gz hence true)\n",
    "condition.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    http://data.insideairbnb.com/the-netherlands/n...\n",
       "1    http://data.insideairbnb.com/the-netherlands/n...\n",
       "2    http://data.insideairbnb.com/the-netherlands/n...\n",
       "3    http://data.insideairbnb.com/the-netherlands/n...\n",
       "4    http://data.insideairbnb.com/the-netherlands/n...\n",
       "Name: links, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_we_want = our_list[condition].reset_index(drop=True) # filter out what we don't need and reset the index, always reset the index otherwise it retains numerical ordering from previous\n",
    "files_we_want.head() # make sure everything when through as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the links we need, let's go ahead and examine how many we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3008,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_we_want.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a nice jump from 20k files all the way down to about 3k. That's still a lot of files to download, and will certainly be a lot of data (size-wise), so how about we have a look at how many files we have per country and, where possible, per city.\n",
    "\n",
    "To get the countries available in our array, we will use another string method from pandas to split the urls by the `\"/\"`, and get the third element. If you notice in the 5 rows above, the 3rd element is the country the file belongs to. We will then use the pandas method `.unique()` to get all of the unique countries in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the split method to seperate strings into seperate strings by a specific parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [http:, , data.insideairbnb.com, the-netherlan...\n",
       "1       [http:, , data.insideairbnb.com, the-netherlan...\n",
       "2       [http:, , data.insideairbnb.com, the-netherlan...\n",
       "3       [http:, , data.insideairbnb.com, the-netherlan...\n",
       "4       [http:, , data.insideairbnb.com, the-netherlan...\n",
       "                              ...                        \n",
       "3003    [http:, , data.insideairbnb.com, australia, wa...\n",
       "3004    [http:, , data.insideairbnb.com, australia, wa...\n",
       "3005    [http:, , data.insideairbnb.com, australia, wa...\n",
       "3006    [http:, , data.insideairbnb.com, australia, wa...\n",
       "3007    [http:, , data.insideairbnb.com, australia, wa...\n",
       "Name: links, Length: 3008, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_we_want.str.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       the-netherlands\n",
       "1       the-netherlands\n",
       "2       the-netherlands\n",
       "3       the-netherlands\n",
       "4       the-netherlands\n",
       "             ...       \n",
       "3003          australia\n",
       "3004          australia\n",
       "3005          australia\n",
       "3006          australia\n",
       "3007          australia\n",
       "Name: links, Length: 3008, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = files_we_want.str.split('/').str.get(3) #selecting the 4th index of strings, in this case the countries\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that countries is another array with the same length as our original `files_we_want` pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the-netherlands', 'belgium', 'united-states', 'greece', 'spain',\n",
       "       'australia', 'china', 'belize', 'italy', 'germany', 'france',\n",
       "       'united-kingdom', 'argentina', 'south-africa', 'denmark',\n",
       "       'ireland', 'switzerland', 'turkey', 'portugal', 'mexico', 'canada',\n",
       "       'norway', 'czech-republic', 'brazil', 'chile', 'singapore',\n",
       "       'sweden', 'taiwan', 'japan', 'austria'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_countries = countries.unique() #checks for unique values \n",
    "unique_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the amount of files we have per country using a for loop. Since the variable `countries` has a pandas Sieries of the same length as the original `files_we_want` variable, we can use it as a mask to count unique countries when they are matched with the elements of our countries variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(countries[countries == 'united-states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "890"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(countries == 'united-states') # f = 0 and t = 1 so sum will show all true booleans, does the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This Is A Title Function'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'this is a title function'.title()  # Makes first letter for every word capitalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The-Netherlands has ------> 59\n",
      "Belgium has ------> 86\n",
      "United-States has ------> 890\n",
      "Greece has ------> 87\n",
      "Spain has ------> 269\n",
      "Australia has ------> 240\n",
      "China has ------> 60\n",
      "Belize has ------> 16\n",
      "Italy has ------> 258\n",
      "Germany has ------> 66\n",
      "France has ------> 120\n",
      "United-Kingdom has ------> 129\n",
      "Argentina has ------> 15\n",
      "South-Africa has ------> 25\n",
      "Denmark has ------> 28\n",
      "Ireland has ------> 47\n",
      "Switzerland has ------> 88\n",
      "Turkey has ------> 26\n",
      "Portugal has ------> 58\n",
      "Mexico has ------> 17\n",
      "Canada has ------> 198\n",
      "Norway has ------> 27\n",
      "Czech-Republic has ------> 26\n",
      "Brazil has ------> 28\n",
      "Chile has ------> 6\n",
      "Singapore has ------> 17\n",
      "Sweden has ------> 26\n",
      "Taiwan has ------> 26\n",
      "Japan has ------> 17\n",
      "Austria has ------> 53\n"
     ]
    }
   ],
   "source": [
    "for country in unique_countries:\n",
    "    print(f\"{country.title()} has ------> {len(files_we_want[countries == country])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "- Find out how many unique cities are represented in our dataset and add them to a list. Assign this list of unique cities to a variable called `unique_cities`. **Hint:** look at how we did this above for the countries.\n",
    "\n",
    "- Print the cities and how many files do we have for each using a for loop. ðŸ‘€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amsterdam', 'antwerp', 'asheville', 'athens', 'austin',\n",
       "       'barcelona', 'barossa-valley', 'barwon-south-west-vic', 'beijing',\n",
       "       'belize', 'bergamo', 'berlin', 'bologna', 'bordeaux', 'boston',\n",
       "       'bristol', 'broward-county', 'brussels', 'buenos-aires',\n",
       "       'cambridge', 'cape-town', 'chicago', 'clark-county-nv', 'columbus',\n",
       "       'copenhagen', 'crete', 'denver', 'dublin', 'edinburgh', 'euskadi',\n",
       "       'florence', 'geneva', 'ghent', 'girona', 'greater-manchester',\n",
       "       'hawaii', 'hong-kong', 'data', 'istanbul', 'jersey-city', 'lisbon',\n",
       "       'london', 'los-angeles', 'lyon', 'madrid', 'malaga', 'mallorca',\n",
       "       'manchester', 'melbourne', 'menorca', 'mexico-city', 'milan',\n",
       "       'montreal', 'munich', 'naples', 'nashville', 'new-brunswick',\n",
       "       'new-orleans', 'new-york-city', 'northern-rivers', 'oakland',\n",
       "       'oslo', 'ottawa', 'pacific-grove', 'paris', 'portland', 'porto',\n",
       "       'prague', 'puglia', 'quebec-city', 'rhode-island',\n",
       "       'rio-de-janeiro', 'rome', 'salem-or', 'san-diego', 'san-francisco',\n",
       "       'san-mateo-county', 'santa-clara-county', 'santa-cruz-county',\n",
       "       'santiago', 'seattle', 'sevilla', 'shanghai', 'sicily',\n",
       "       'singapore', 'south-aegean', 'stockholm', 'sydney', 'taipei',\n",
       "       'tasmania', 'thessaloniki', 'tokyo', 'toronto', 'trentino',\n",
       "       'twin-cities-msa', 'valencia', 'vancouver', 'vaud', 'venice',\n",
       "       'victoria', 'vienna', 'washington-dc', 'western-australia'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = files_we_want.str.split('/').str.get(5) \n",
    "unique_cities = cities.unique()\n",
    "unique_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam has ------> 59\n",
      "Antwerp has ------> 29\n",
      "Asheville has ------> 29\n",
      "Athens has ------> 30\n",
      "Austin has ------> 33\n",
      "Barcelona has ------> 52\n",
      "Barossa-Valley has ------> 28\n",
      "Barwon-South-West-Vic has ------> 24\n",
      "Beijing has ------> 27\n",
      "Belize has ------> 16\n",
      "Bergamo has ------> 26\n",
      "Berlin has ------> 49\n",
      "Bologna has ------> 28\n",
      "Bordeaux has ------> 31\n",
      "Boston has ------> 33\n",
      "Bristol has ------> 27\n",
      "Broward-County has ------> 17\n",
      "Brussels has ------> 29\n",
      "Buenos-Aires has ------> 15\n",
      "Cambridge has ------> 21\n",
      "Cape-Town has ------> 25\n",
      "Chicago has ------> 31\n",
      "Clark-County-Nv has ------> 26\n",
      "Columbus has ------> 26\n",
      "Copenhagen has ------> 28\n",
      "Crete has ------> 18\n",
      "Denver has ------> 28\n",
      "Dublin has ------> 33\n",
      "Edinburgh has ------> 37\n",
      "Euskadi has ------> 26\n",
      "Florence has ------> 31\n",
      "Geneva has ------> 45\n",
      "Ghent has ------> 28\n",
      "Girona has ------> 25\n",
      "Greater-Manchester has ------> 28\n",
      "Hawaii has ------> 25\n",
      "Hong-Kong has ------> 28\n",
      "Data has ------> 14\n",
      "Istanbul has ------> 26\n",
      "Jersey-City has ------> 16\n",
      "Lisbon has ------> 29\n",
      "London has ------> 36\n",
      "Los-Angeles has ------> 45\n",
      "Lyon has ------> 30\n",
      "Madrid has ------> 36\n",
      "Malaga has ------> 28\n",
      "Mallorca has ------> 30\n",
      "Manchester has ------> 1\n",
      "Melbourne has ------> 37\n",
      "Menorca has ------> 26\n",
      "Mexico-City has ------> 17\n",
      "Milan has ------> 30\n",
      "Montreal has ------> 31\n",
      "Munich has ------> 17\n",
      "Naples has ------> 28\n",
      "Nashville has ------> 35\n",
      "New-Brunswick has ------> 12\n",
      "New-Orleans has ------> 58\n",
      "New-York-City has ------> 68\n",
      "Northern-Rivers has ------> 30\n",
      "Oakland has ------> 29\n",
      "Oslo has ------> 27\n",
      "Ottawa has ------> 20\n",
      "Pacific-Grove has ------> 27\n",
      "Paris has ------> 59\n",
      "Portland has ------> 58\n",
      "Porto has ------> 29\n",
      "Prague has ------> 26\n",
      "Puglia has ------> 25\n",
      "Quebec-City has ------> 38\n",
      "Rhode-Island has ------> 22\n",
      "Rio-De-Janeiro has ------> 28\n",
      "Rome has ------> 31\n",
      "Salem-Or has ------> 25\n",
      "San-Diego has ------> 30\n",
      "San-Francisco has ------> 63\n",
      "San-Mateo-County has ------> 4\n",
      "Santa-Clara-County has ------> 25\n",
      "Santa-Cruz-County has ------> 27\n",
      "Santiago has ------> 6\n",
      "Seattle has ------> 29\n",
      "Sevilla has ------> 26\n",
      "Shanghai has ------> 5\n",
      "Sicily has ------> 25\n",
      "Singapore has ------> 17\n",
      "South-Aegean has ------> 18\n",
      "Stockholm has ------> 26\n",
      "Sydney has ------> 42\n",
      "Taipei has ------> 26\n",
      "Tasmania has ------> 52\n",
      "Thessaloniki has ------> 21\n",
      "Tokyo has ------> 17\n",
      "Toronto has ------> 37\n",
      "Trentino has ------> 1\n",
      "Twin-Cities-Msa has ------> 28\n",
      "Valencia has ------> 20\n",
      "Vancouver has ------> 34\n",
      "Vaud has ------> 43\n",
      "Venice has ------> 33\n",
      "Victoria has ------> 26\n",
      "Vienna has ------> 53\n",
      "Washington-Dc has ------> 32\n",
      "Western-Australia has ------> 27\n"
     ]
    }
   ],
   "source": [
    "for city in unique_cities:\n",
    "    print(f\"{city.title()} has ------> {len(files_we_want[cities == city])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers below! Don't peak! ðŸ‘€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amsterdam', 'antwerp', 'asheville', 'athens', 'austin',\n",
       "       'barcelona', 'barossa-valley', 'barwon-south-west-vic', 'beijing',\n",
       "       'belize', 'bergamo', 'berlin', 'bologna', 'bordeaux', 'boston',\n",
       "       'bristol', 'broward-county', 'brussels', 'buenos-aires',\n",
       "       'cambridge', 'cape-town', 'chicago', 'clark-county-nv', 'columbus',\n",
       "       'copenhagen', 'crete', 'denver', 'dublin', 'edinburgh', 'euskadi',\n",
       "       'florence', 'geneva', 'ghent', 'girona', 'greater-manchester',\n",
       "       'hawaii', 'hong-kong', 'data', 'istanbul', 'jersey-city', 'lisbon',\n",
       "       'london', 'los-angeles', 'lyon', 'madrid', 'malaga', 'mallorca',\n",
       "       'manchester', 'melbourne', 'menorca', 'mexico-city', 'milan',\n",
       "       'montreal', 'munich', 'naples', 'nashville', 'new-brunswick',\n",
       "       'new-orleans', 'new-york-city', 'northern-rivers', 'oakland',\n",
       "       'oslo', 'ottawa', 'pacific-grove', 'paris', 'portland', 'porto',\n",
       "       'prague', 'puglia', 'quebec-city', 'rhode-island',\n",
       "       'rio-de-janeiro', 'rome', 'salem-or', 'san-diego', 'san-francisco',\n",
       "       'san-mateo-county', 'santa-clara-county', 'santa-cruz-county',\n",
       "       'santiago', 'seattle', 'sevilla', 'shanghai', 'sicily',\n",
       "       'singapore', 'south-aegean', 'stockholm', 'sydney', 'taipei',\n",
       "       'tasmania', 'thessaloniki', 'tokyo', 'toronto', 'trentino',\n",
       "       'twin-cities-msa', 'valencia', 'vancouver', 'vaud', 'venice',\n",
       "       'victoria', 'vienna', 'washington-dc', 'western-australia'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = files_we_want.str.split('/').str.get(5)\n",
    "unique_cities = cities.unique()\n",
    "unique_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amsterdam has ------> 59\n",
      "Antwerp has ------> 29\n",
      "Asheville has ------> 29\n",
      "Athens has ------> 30\n",
      "Austin has ------> 33\n",
      "Barcelona has ------> 52\n",
      "Barossa-Valley has ------> 28\n",
      "Barwon-South-West-Vic has ------> 24\n",
      "Beijing has ------> 27\n",
      "Belize has ------> 16\n",
      "Bergamo has ------> 26\n",
      "Berlin has ------> 49\n",
      "Bologna has ------> 28\n",
      "Bordeaux has ------> 31\n",
      "Boston has ------> 33\n",
      "Bristol has ------> 27\n",
      "Broward-County has ------> 17\n",
      "Brussels has ------> 29\n",
      "Buenos-Aires has ------> 15\n",
      "Cambridge has ------> 21\n",
      "Cape-Town has ------> 25\n",
      "Chicago has ------> 31\n",
      "Clark-County-Nv has ------> 26\n",
      "Columbus has ------> 26\n",
      "Copenhagen has ------> 28\n",
      "Crete has ------> 18\n",
      "Denver has ------> 28\n",
      "Dublin has ------> 33\n",
      "Edinburgh has ------> 37\n",
      "Euskadi has ------> 26\n",
      "Florence has ------> 31\n",
      "Geneva has ------> 45\n",
      "Ghent has ------> 28\n",
      "Girona has ------> 25\n",
      "Greater-Manchester has ------> 28\n",
      "Hawaii has ------> 25\n",
      "Hong-Kong has ------> 28\n",
      "Data has ------> 14\n",
      "Istanbul has ------> 26\n",
      "Jersey-City has ------> 16\n",
      "Lisbon has ------> 29\n",
      "London has ------> 36\n",
      "Los-Angeles has ------> 45\n",
      "Lyon has ------> 30\n",
      "Madrid has ------> 36\n",
      "Malaga has ------> 28\n",
      "Mallorca has ------> 30\n",
      "Manchester has ------> 1\n",
      "Melbourne has ------> 37\n",
      "Menorca has ------> 26\n",
      "Mexico-City has ------> 17\n",
      "Milan has ------> 30\n",
      "Montreal has ------> 31\n",
      "Munich has ------> 17\n",
      "Naples has ------> 28\n",
      "Nashville has ------> 35\n",
      "New-Brunswick has ------> 12\n",
      "New-Orleans has ------> 58\n",
      "New-York-City has ------> 68\n",
      "Northern-Rivers has ------> 30\n",
      "Oakland has ------> 29\n",
      "Oslo has ------> 27\n",
      "Ottawa has ------> 20\n",
      "Pacific-Grove has ------> 27\n",
      "Paris has ------> 59\n",
      "Portland has ------> 58\n",
      "Porto has ------> 29\n",
      "Prague has ------> 26\n",
      "Puglia has ------> 25\n",
      "Quebec-City has ------> 38\n",
      "Rhode-Island has ------> 22\n",
      "Rio-De-Janeiro has ------> 28\n",
      "Rome has ------> 31\n",
      "Salem-Or has ------> 25\n",
      "San-Diego has ------> 30\n",
      "San-Francisco has ------> 63\n",
      "San-Mateo-County has ------> 4\n",
      "Santa-Clara-County has ------> 25\n",
      "Santa-Cruz-County has ------> 27\n",
      "Santiago has ------> 6\n",
      "Seattle has ------> 29\n",
      "Sevilla has ------> 26\n",
      "Shanghai has ------> 5\n",
      "Sicily has ------> 25\n",
      "Singapore has ------> 17\n",
      "South-Aegean has ------> 18\n",
      "Stockholm has ------> 26\n",
      "Sydney has ------> 42\n",
      "Taipei has ------> 26\n",
      "Tasmania has ------> 52\n",
      "Thessaloniki has ------> 21\n",
      "Tokyo has ------> 17\n",
      "Toronto has ------> 37\n",
      "Trentino has ------> 1\n",
      "Twin-Cities-Msa has ------> 28\n",
      "Valencia has ------> 20\n",
      "Vancouver has ------> 34\n",
      "Vaud has ------> 43\n",
      "Venice has ------> 33\n",
      "Victoria has ------> 26\n",
      "Vienna has ------> 53\n",
      "Washington-Dc has ------> 32\n",
      "Western-Australia has ------> 27\n"
     ]
    }
   ],
   "source": [
    "for city in unique_cities:\n",
    "    print(f\"{city.title()} has ------> {len(files_we_want[cities == city])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now pick 2 countries and a city we'd like to visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_country = 'japan'\n",
    "my_country2 = 'belgium'\n",
    "my_city = 'cape-town'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is one of the most important functions in the whole notebook as it is the one that is going to allow us to download the data we need from Inside Airbnb.\n",
    "\n",
    "The function takes in the following arguments:\n",
    "- `urls` --> This is strictly a pandas series with the list of urls we need\n",
    "- `country_city` --> This would the country or city you want to get data for\n",
    "- `path_to_files` --> This is where the data will be downloaded to\n",
    "- `country_city_unique` --> This is the iterable of unique countries or cities where Airbnb operates in\n",
    "- `unique_num` --> If you do not need all files available for `country_city`, you can specify how many you need. Default is all files\n",
    "\n",
    "The function operates as follows:\n",
    "\n",
    "1. It first checks whether the country you have picked is in the list of unique countries\n",
    "2. Then it creates a boolean array (aka a mask)\n",
    "3. Passes it through our pandas series containing the urls to filter out the countries you don't need\n",
    "4. Then it downloads the files you want and\n",
    "5. Saves them into a new folder it creates called `raw_data` in the path you provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_me_specific_data(urls, country_city, path_to_files, country_city_unique, unique_num):\n",
    "    \n",
    "    \"\"\"\n",
    "    urls: This is a pandas Series with the listings urls in it\n",
    "    country_city: string with the name of the country or city you would like to get data from\n",
    "    path_to_file: plain data foldet where the data will go to\n",
    "    country_city_unique: interable with the unique countries or cities\n",
    "    unique_num: Default None. If specified, it will download that amount of files\n",
    "    \"\"\"\n",
    "    \n",
    "    if country_city in country_city_unique: # we go over every country\n",
    "        \n",
    "        condition = urls.str.contains(country_city.lower()) # check whether it exists in our list of urls and create a mask\n",
    "        data_we_need = urls[condition] # we pass that mask to our pandas series\n",
    "        new_dir = check_or_add(path_to_files, country_city + '_data', 'raw_data') # create a new directory for the raw data\n",
    "        \n",
    "        if unique_num: # we first check if a unique number of files was specified\n",
    "            \n",
    "            num = 0\n",
    "            \n",
    "            while num < unique_num: # loop until we reach that point\n",
    "                \n",
    "                try: # we first try to download the file with wget. if wget doesn't work, we try with urllib\n",
    "                    wget.download(data_we_need.iloc[num], os.path.join(new_dir, f'{country_city}_{num}.csv.gz'))\n",
    "                except:\n",
    "                    try: # if urllib doesn't work, we move on to the next one\n",
    "                        urllib.request.urlretrieve(data_we_need.iloc[num], os.path.join(new_dir, f'{country_city}_{num}.csv.gz'))\n",
    "                    except:\n",
    "                        continue\n",
    "                num += 1\n",
    "        else:\n",
    "            \n",
    "            for num, data in enumerate(data_we_need): # iterate over the links we want\n",
    "                \n",
    "                try: # we first try to download the file with wget. if wget doesn't work, we try with urllib\n",
    "                    wget.download(data, os.path.join(new_dir, f'{country_city}_{num}.csv.gz'))\n",
    "                except:\n",
    "                    try: \n",
    "                        urllib.request.urlretrieve(data, os.path.join(new_dir, f'{country_city}_{num}.csv.gz'))\n",
    "                    except:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our new function to use and get the first batch of data we will be using. In honor to our host, we will be picking Japan as our first country,\n",
    "\n",
    "When doing this on your own, here is a table with the countries, the amount of files available, the total size of the uncompressed and the compressed files, and the average size per file. The recommended way to pick a country and the amount of files you should download goes as follows:\n",
    "1. Pick a reasonable GB size for your project (somewhere between 2 and 4 GB should be perfect to get started on your own).\n",
    "2. Pick a country.\n",
    "3. If the number of files in that country don't amount to the GB size you choose in step 1, pick another country or pick multiple countries until you have the desired amount of data.\n",
    "4. If you want pick multiple countries but the total size of one or more of them is too large for what you think your computer can handle, divide the total GB size you need by the GB space you have left and that would be the amount of files you should to download.\n",
    "5. Use the `get_me_specific_data()` function with the appropriate parameters and wait for a bit.\n",
    "\n",
    "\n",
    "| Country         | # of Cities | # of Files | GB Size Compressed  | GB Size Decompressed|\n",
    "|:----------------|:------------|:-----------|:--------------------|:--------------------|\n",
    "| The-Netherlands |     1       |     58     |        851 M        |        3.6 G        |\n",
    "| Belgium         |     3       |     83     |        245 M        |        1.0 G        |\n",
    "| United-States   |    28       |    859     |        8.4 G        |       35.0 G        |\n",
    "| Greece          |     4       |     82     |        902 M        |        3.8 G        |\n",
    "| Spain           |     9       |    259     |        2.7 G        |       12.0 G        |\n",
    "| Australia       |     7       |    233     |        2.6 G        |       11.0 G        |\n",
    "| China           |     3       |     57     |        1.1 G        |        4.9 G        |\n",
    "| Belize          |     1       |     15     |         38 M        |        180 M        |\n",
    "| Italy           |    10       |    246     |        4.0 G        |       16.0 G        |\n",
    "| Germany         |     2       |     63     |        894 M        |        3.6 G        |\n",
    "| France          |     3       |    117     |        3.1 G        |       13.0 G        |\n",
    "| United-Kingdom  |     5       |    125     |        2.7 G        |       11.0 G        |\n",
    "| Argentina       |     1       |     14     |        272 M        |        1.1 G        |\n",
    "| South-Africa    |     1       |     24     |        452 M        |        1.9 G        |\n",
    "| Denmark         |     1       |     27     |        505 M        |        2.2 G        |\n",
    "| Ireland         |     2       |     45     |        550 M        |        2.3 G        |\n",
    "| Switzerland     |     2       |     86     |        200 M        |        858 M        |\n",
    "| Turkey          |     1       |     25     |        275 M        |        1.2 G        |\n",
    "| Portugal        |     2       |     56     |        879 M        |        3.7 G        |\n",
    "| Mexico          |     1       |     16     |        279 M        |        1.1 G        |\n",
    "| Canada          |     7       |    191     |        1.4 G        |        6.0 G        |\n",
    "| Norway          |     1       |     26     |        156 M        |        663 M        |\n",
    "| Czech-Republic  |     1       |     25     |        317 M        |        1.3 G        |\n",
    "| Brazil          |     1       |     27     |        731 M        |        2.9 G        |\n",
    "| Chile           |     1       |      5     |         52 M        |        232 M        |\n",
    "| Singapore       |     1       |     16     |        102 M        |        516 M        |\n",
    "| Sweden          |     1       |     25     |        129 M        |        561 M        |\n",
    "| Taiwan          |     1       |     25     |        281 M        |        1.1 G        |\n",
    "| Japan           |     1       |     16     |        248 M        |        1.2 G        |\n",
    "| Austria         |     1       |     52     |        433 M        |        1.8 G        |\n",
    "\n",
    "Let's now put our function to use and get the data we need for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "get_me_specific_data(files_we_want, my_country, path, unique_countries, 4)\n",
    "get_me_specific_data(files_we_want, my_country2, path, unique_countries, 4)\n",
    "get_me_specific_data(files_we_want, my_city, path, unique_cities, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the data we have gathered so far to see if we got back what we wanted from Inside Airbnb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "country1_raw_files = check_or_add(path, my_country + '_data', 'raw_data') # let's add our new raw_data path to a variable\n",
    "country2_raw_files = check_or_add(path, my_country2 + '_data', 'raw_data')\n",
    "city_raw_files = check_or_add(path, my_city + '_data', 'raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `os.listdir()` helps us see the files inside a directory/folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of files we downloaded for japan --> 4\n",
      "Amount of files we downloaded for belgium --> 8\n",
      "Amount of files we downloaded for cape-town --> 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Amount of files we downloaded for {my_country} --> {len(os.listdir(country1_raw_files))}\")\n",
    "print(f\"Amount of files we downloaded for {my_country2} --> {len(os.listdir(country2_raw_files))}\")\n",
    "print(f\"Amount of files we downloaded for {my_city} --> {len(os.listdir(city_raw_files))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, it seems like we got all of the files we wanted so let's look under the hood and examine one to see what we've got.\n",
    "\n",
    "Since pandas has a `compression` parameter, we will not worry about decompressing our files with other tools and use a pandas DataFrame in the next few cells. You can think of a pandas DataFrame as many pandas Series combined into one data structure, or as a spreadsheet with rows and columns. You can also pass in Python dictionaries, two-dimensional lists and arrays, tuples, etc. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_A</th>\n",
       "      <th>column_B</th>\n",
       "      <th>column_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_A  column_B  column_C\n",
       "0         0         5        15\n",
       "1         1         6        16\n",
       "2         2         7        17\n",
       "3         3         8        18\n",
       "4         4         9        19"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df = pd.DataFrame({'column_A': range(5),\n",
    "                       'column_B': range(5, 10),\n",
    "                       'column_C': range(15, 20)})\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access a pandas column using the same convention used when accessing specific keys from a dictionary. The result will be a pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: column_A, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df['column_A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All operations (or almost all) that can be done in a pandas Series can be done in a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_A</th>\n",
       "      <th>column_B</th>\n",
       "      <th>column_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_A  column_B  column_C\n",
       "3         3         8        18\n",
       "4         4         9        19"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df[toy_df['column_A'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_A     2.0\n",
       "column_B     7.0\n",
       "column_C    17.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df.mean() # provides us with the mean of all three columns and moves the column names to the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know a bit more about pandas DataFrames, let's continue and examine one of the many datasets we just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_num = 1 # pick a number for the file you want to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14715 entries, 0 to 14714\n",
      "Columns: 106 entries, id to reviews_per_month\n",
      "dtypes: float64(23), int64(21), object(62)\n",
      "memory usage: 158.2 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(country1_raw_files, f'{my_country}_{file_num}.csv.gz'), compression='gzip', \n",
    "                 low_memory=False, encoding='utf-8')\n",
    "\n",
    "df.info(memory_usage='deep') # this will tells us exactly how much space this dataset is occupying in our computer's memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the previous random file has about 15k rows, 106 columns, and it has a decompressed size of ~160MB. Let's have a quick glance at the first few rows of the file with the `.head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>notes</th>\n",
       "      <th>transit</th>\n",
       "      <th>access</th>\n",
       "      <th>interaction</th>\n",
       "      <th>house_rules</th>\n",
       "      <th>thumbnail_url</th>\n",
       "      <th>medium_url</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>xl_picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_url</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <th>host_picture_url</th>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_verifications</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>street</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>neighbourhood_group_cleansed</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>market</th>\n",
       "      <th>smart_location</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>price</th>\n",
       "      <th>weekly_price</th>\n",
       "      <th>monthly_price</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>cleaning_fee</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>maximum_minimum_nights</th>\n",
       "      <th>minimum_maximum_nights</th>\n",
       "      <th>maximum_maximum_nights</th>\n",
       "      <th>minimum_nights_avg_ntm</th>\n",
       "      <th>maximum_nights_avg_ntm</th>\n",
       "      <th>calendar_updated</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>review_scores_accuracy</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>is_business_travel_ready</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35303</td>\n",
       "      <td>https://www.airbnb.com/rooms/35303</td>\n",
       "      <td>20200625032351</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>La Casa Gaienmae C Harajuku, Omotesando is nearby</td>\n",
       "      <td>This shared flat is locating at very close to ...</td>\n",
       "      <td>This apartment is 3 bedroom flat shared with t...</td>\n",
       "      <td>This shared flat is locating at very close to ...</td>\n",
       "      <td>none</td>\n",
       "      <td>10 min walking to Harajuku ~ Urahara ~ Omotesa...</td>\n",
       "      <td>Current tenants are living in this flat over 2...</td>\n",
       "      <td>5min to subway, 10min to JR stations, you can ...</td>\n",
       "      <td>Your private room, Kitchen, Bathroom, Toilet, ...</td>\n",
       "      <td>I provide common space cleaning twice a week. ...</td>\n",
       "      <td>If you would like to stay monthly, there is a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/67365319/c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151977</td>\n",
       "      <td>https://www.airbnb.com/users/show/151977</td>\n",
       "      <td>Miyuki</td>\n",
       "      <td>2010-06-25</td>\n",
       "      <td>Shibuya, Tokyo, Japan</td>\n",
       "      <td>Hi I am Miyuki Kanda. I run a real estate &amp; pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>https://a0.muscache.com/im/users/151977/profil...</td>\n",
       "      <td>https://a0.muscache.com/im/users/151977/profil...</td>\n",
       "      <td>Shibuya District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['email', 'phone', 'facebook', 'reviews', 'jum...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Shibuya, Tokyo, Japan</td>\n",
       "      <td>Shibuya District</td>\n",
       "      <td>Shibuya Ku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shibuya</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>150-0001</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Shibuya, Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>35.67152</td>\n",
       "      <td>139.71203</td>\n",
       "      <td>t</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Internet,Wifi,Kitchen,\"Paid parking off pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$4,163.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$110,000.00</td>\n",
       "      <td>$30,000.00</td>\n",
       "      <td>$5,000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>1125</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>20 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-12-28</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>t</td>\n",
       "      <td>Other reasons | \\nå¼Šç¤¾ã¯ä¸å‹•ç”£äº‹æ¥­è€…ã§ã‚ã‚Šè³ƒè²¸ä½å®…ç®¡ç†äº‹æ¥­è€…ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197677</td>\n",
       "      <td>https://www.airbnb.com/rooms/197677</td>\n",
       "      <td>20200625032351</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>Oshiage Holiday Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are happy to welcome you to our apartment, ...</td>\n",
       "      <td>We are happy to welcome you to our apartment, ...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1. Smoking is NOT allowed inside the property....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/38437056/d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>964081</td>\n",
       "      <td>https://www.airbnb.com/users/show/964081</td>\n",
       "      <td>Yoshimi &amp; Marek</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Would love to travel all over the world and me...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100%</td>\n",
       "      <td>85%</td>\n",
       "      <td>t</td>\n",
       "      <td>https://a0.muscache.com/im/users/964081/profil...</td>\n",
       "      <td>https://a0.muscache.com/im/users/964081/profil...</td>\n",
       "      <td>Sumida District</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['email', 'phone', 'facebook', 'reviews', 'jum...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Sumida, Tokyo, Japan</td>\n",
       "      <td>Sumida District</td>\n",
       "      <td>Sumida Ku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumida</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Sumida, Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>35.71721</td>\n",
       "      <td>139.82596</td>\n",
       "      <td>f</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Futon</td>\n",
       "      <td>{TV,Internet,Wifi,\"Air conditioning\",Kitchen,\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$10,993.00</td>\n",
       "      <td>$66,000.00</td>\n",
       "      <td>$240,000.00</td>\n",
       "      <td>$40,000.00</td>\n",
       "      <td>$5,000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>365</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>3.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>28</td>\n",
       "      <td>46</td>\n",
       "      <td>76</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>165</td>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-21</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>t</td>\n",
       "      <td>M130003350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289597</td>\n",
       "      <td>https://www.airbnb.com/rooms/289597</td>\n",
       "      <td>20200625032351</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>Private apt in central Tokyo #203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>::::::::::::::::::::::::::::::::::::::::::::::...</td>\n",
       "      <td>::::::::::::::::::::::::::::::::::::::::::::::...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can not see you in person as I don't live in...</td>\n",
       "      <td>No smoking inside. No Parties or loud noises. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/6454753/a8...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341577</td>\n",
       "      <td>https://www.airbnb.com/users/show/341577</td>\n",
       "      <td>Hide&amp;Kei</td>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "      <td>We love travelling all over the world.\\r\\nWe a...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100%</td>\n",
       "      <td>80%</td>\n",
       "      <td>f</td>\n",
       "      <td>https://a0.muscache.com/im/users/341577/profil...</td>\n",
       "      <td>https://a0.muscache.com/im/users/341577/profil...</td>\n",
       "      <td>Nerima District</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['email', 'phone', 'reviews', 'jumio', 'govern...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Nerima, Tokyo, Japan</td>\n",
       "      <td>Nerima District</td>\n",
       "      <td>Nerima Ku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nerima</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Nerima, Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>35.74267</td>\n",
       "      <td>139.65810</td>\n",
       "      <td>f</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Wifi,\"Air conditioning\",Kitchen,\"Hot tub\",...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>$4,163.00</td>\n",
       "      <td>$28,818.00</td>\n",
       "      <td>$149,426.00</td>\n",
       "      <td>$32,020.00</td>\n",
       "      <td>$5,337.00</td>\n",
       "      <td>1</td>\n",
       "      <td>$1,067.00</td>\n",
       "      <td>28</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>26.5</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>165</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>113</td>\n",
       "      <td>6</td>\n",
       "      <td>2012-06-15</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>t</td>\n",
       "      <td>Other reasons | 1ã‹æœˆä»¥ä¸Šã®è³ƒè²¸å€Ÿå¥‘ç´„ã®ã¿å¯¾å¿œã¨ã™ã‚‹ã€‚ã‚²ã‚¹ãƒˆã«ã¯è³ƒè²¸å¥‘ç´„ã®ç½²...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370759</td>\n",
       "      <td>https://www.airbnb.com/rooms/370759</td>\n",
       "      <td>20200625032351</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>Cozy flat #203, local area YET 10 mins to shib...</td>\n",
       "      <td>So close to busy centers, yet so peaceful! Jus...</td>\n",
       "      <td>Cozy and Relaxing, at home feeling in a reside...</td>\n",
       "      <td>So close to busy centers, yet so peaceful! Jus...</td>\n",
       "      <td>none</td>\n",
       "      <td>Peaceful and residential area just 10 mins awa...</td>\n",
       "      <td>January - February - July - August: During tho...</td>\n",
       "      <td>3 mins away to the station. Nice walks all aro...</td>\n",
       "      <td>It is your own private flat during your stay i...</td>\n",
       "      <td>We are very near if needed let us know. Will b...</td>\n",
       "      <td>Please check the following: -Thank you to put ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/34594282-f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1573631</td>\n",
       "      <td>https://www.airbnb.com/users/show/1573631</td>\n",
       "      <td>Gilles,Mayumi,Taiki</td>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>Imari, Saga, Japan</td>\n",
       "      <td>We are a French-Japanese couple working betwee...</td>\n",
       "      <td>within a day</td>\n",
       "      <td>100%</td>\n",
       "      <td>92%</td>\n",
       "      <td>t</td>\n",
       "      <td>https://a0.muscache.com/im/users/1573631/profi...</td>\n",
       "      <td>https://a0.muscache.com/im/users/1573631/profi...</td>\n",
       "      <td>Setagaya District</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['email', 'phone', 'facebook', 'reviews', 'jum...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Tokyo, Tokyo, Japan</td>\n",
       "      <td>Setagaya District</td>\n",
       "      <td>Setagaya Ku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>156-0042</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>35.66443</td>\n",
       "      <td>139.65707</td>\n",
       "      <td>t</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Internet,Wifi,\"Air conditioning\",Kitchen,\"...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>$7,044.00</td>\n",
       "      <td>$56,009.00</td>\n",
       "      <td>$198,032.00</td>\n",
       "      <td>$20,000.00</td>\n",
       "      <td>$6,000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>720</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>3 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>86</td>\n",
       "      <td>361</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-03-25</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>t</td>\n",
       "      <td>Other reasons | We called Setagaya ku hokenjo ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700253</td>\n",
       "      <td>https://www.airbnb.com/rooms/700253</td>\n",
       "      <td>20200625032351</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>Private apt in central Tokyo #201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>::::::::::::::::::::::::::::::::::::::::::::::...</td>\n",
       "      <td>::::::::::::::::::::::::::::::::::::::::::::::...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can not see you in person as I don't live in...</td>\n",
       "      <td>No smoking inside. No Parties or loud noises. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/9888693/af...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341577</td>\n",
       "      <td>https://www.airbnb.com/users/show/341577</td>\n",
       "      <td>Hide&amp;Kei</td>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "      <td>We love travelling all over the world.\\r\\nWe a...</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100%</td>\n",
       "      <td>80%</td>\n",
       "      <td>f</td>\n",
       "      <td>https://a0.muscache.com/im/users/341577/profil...</td>\n",
       "      <td>https://a0.muscache.com/im/users/341577/profil...</td>\n",
       "      <td>Nerima District</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['email', 'phone', 'reviews', 'jumio', 'govern...</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Nerima, Tokyo, Japan</td>\n",
       "      <td>Nerima District</td>\n",
       "      <td>Nerima Ku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nerima</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Nerima, Japan</td>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>35.74264</td>\n",
       "      <td>139.65832</td>\n",
       "      <td>f</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>{TV,Internet,Wifi,\"Air conditioning\",Kitchen,\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$3,949.00</td>\n",
       "      <td>$28,818.00</td>\n",
       "      <td>$149,426.00</td>\n",
       "      <td>$32,020.00</td>\n",
       "      <td>$5,337.00</td>\n",
       "      <td>1</td>\n",
       "      <td>$1,067.00</td>\n",
       "      <td>28</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>27.3</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>t</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>353</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-10-17</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>t</td>\n",
       "      <td>Other reasons | 1ã‹æœˆä»¥ä¸Šã®è³ƒè²¸å€Ÿå¥‘ç´„ã®ã¿å¯¾å¿œã¨ã™ã‚‹ã€‚ã‚²ã‚¹ãƒˆã«ã¯è³ƒè²¸å¥‘ç´„ã®ç½²...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          listing_url       scrape_id last_scraped  \\\n",
       "0   35303   https://www.airbnb.com/rooms/35303  20200625032351   2020-06-25   \n",
       "1  197677  https://www.airbnb.com/rooms/197677  20200625032351   2020-06-25   \n",
       "2  289597  https://www.airbnb.com/rooms/289597  20200625032351   2020-06-25   \n",
       "3  370759  https://www.airbnb.com/rooms/370759  20200625032351   2020-06-25   \n",
       "4  700253  https://www.airbnb.com/rooms/700253  20200625032351   2020-06-25   \n",
       "\n",
       "                                                name  \\\n",
       "0  La Casa Gaienmae C Harajuku, Omotesando is nearby   \n",
       "1                          Oshiage Holiday Apartment   \n",
       "2                  Private apt in central Tokyo #203   \n",
       "3  Cozy flat #203, local area YET 10 mins to shib...   \n",
       "4                  Private apt in central Tokyo #201   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This shared flat is locating at very close to ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  So close to busy centers, yet so peaceful! Jus...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               space  \\\n",
       "0  This apartment is 3 bedroom flat shared with t...   \n",
       "1  We are happy to welcome you to our apartment, ...   \n",
       "2  ::::::::::::::::::::::::::::::::::::::::::::::...   \n",
       "3  Cozy and Relaxing, at home feeling in a reside...   \n",
       "4  ::::::::::::::::::::::::::::::::::::::::::::::...   \n",
       "\n",
       "                                         description experiences_offered  \\\n",
       "0  This shared flat is locating at very close to ...                none   \n",
       "1  We are happy to welcome you to our apartment, ...                none   \n",
       "2  ::::::::::::::::::::::::::::::::::::::::::::::...                none   \n",
       "3  So close to busy centers, yet so peaceful! Jus...                none   \n",
       "4  ::::::::::::::::::::::::::::::::::::::::::::::...                none   \n",
       "\n",
       "                               neighborhood_overview  \\\n",
       "0  10 min walking to Harajuku ~ Urahara ~ Omotesa...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  Peaceful and residential area just 10 mins awa...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                               notes  \\\n",
       "0  Current tenants are living in this flat over 2...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  January - February - July - August: During tho...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             transit  \\\n",
       "0  5min to subway, 10min to JR stations, you can ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  3 mins away to the station. Nice walks all aro...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              access  \\\n",
       "0  Your private room, Kitchen, Bathroom, Toilet, ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  It is your own private flat during your stay i...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         interaction  \\\n",
       "0  I provide common space cleaning twice a week. ...   \n",
       "1                                                NaN   \n",
       "2  I can not see you in person as I don't live in...   \n",
       "3  We are very near if needed let us know. Will b...   \n",
       "4  I can not see you in person as I don't live in...   \n",
       "\n",
       "                                         house_rules  thumbnail_url  \\\n",
       "0  If you would like to stay monthly, there is a ...            NaN   \n",
       "1  1. Smoking is NOT allowed inside the property....            NaN   \n",
       "2  No smoking inside. No Parties or loud noises. ...            NaN   \n",
       "3  Please check the following: -Thank you to put ...            NaN   \n",
       "4  No smoking inside. No Parties or loud noises. ...            NaN   \n",
       "\n",
       "   medium_url                                        picture_url  \\\n",
       "0         NaN  https://a0.muscache.com/im/pictures/67365319/c...   \n",
       "1         NaN  https://a0.muscache.com/im/pictures/38437056/d...   \n",
       "2         NaN  https://a0.muscache.com/im/pictures/6454753/a8...   \n",
       "3         NaN  https://a0.muscache.com/im/pictures/34594282-f...   \n",
       "4         NaN  https://a0.muscache.com/im/pictures/9888693/af...   \n",
       "\n",
       "   xl_picture_url  host_id                                   host_url  \\\n",
       "0             NaN   151977   https://www.airbnb.com/users/show/151977   \n",
       "1             NaN   964081   https://www.airbnb.com/users/show/964081   \n",
       "2             NaN   341577   https://www.airbnb.com/users/show/341577   \n",
       "3             NaN  1573631  https://www.airbnb.com/users/show/1573631   \n",
       "4             NaN   341577   https://www.airbnb.com/users/show/341577   \n",
       "\n",
       "             host_name  host_since          host_location  \\\n",
       "0               Miyuki  2010-06-25  Shibuya, Tokyo, Japan   \n",
       "1      Yoshimi & Marek  2011-08-13                  Tokyo   \n",
       "2             Hide&Kei  2011-01-10           Tokyo, Japan   \n",
       "3  Gilles,Mayumi,Taiki  2012-01-06     Imari, Saga, Japan   \n",
       "4             Hide&Kei  2011-01-10           Tokyo, Japan   \n",
       "\n",
       "                                          host_about  host_response_time  \\\n",
       "0  Hi I am Miyuki Kanda. I run a real estate & pr...                 NaN   \n",
       "1  Would love to travel all over the world and me...  within a few hours   \n",
       "2  We love travelling all over the world.\\r\\nWe a...  within a few hours   \n",
       "3  We are a French-Japanese couple working betwee...        within a day   \n",
       "4  We love travelling all over the world.\\r\\nWe a...  within a few hours   \n",
       "\n",
       "  host_response_rate host_acceptance_rate host_is_superhost  \\\n",
       "0                NaN                  NaN                 f   \n",
       "1               100%                  85%                 t   \n",
       "2               100%                  80%                 f   \n",
       "3               100%                  92%                 t   \n",
       "4               100%                  80%                 f   \n",
       "\n",
       "                                  host_thumbnail_url  \\\n",
       "0  https://a0.muscache.com/im/users/151977/profil...   \n",
       "1  https://a0.muscache.com/im/users/964081/profil...   \n",
       "2  https://a0.muscache.com/im/users/341577/profil...   \n",
       "3  https://a0.muscache.com/im/users/1573631/profi...   \n",
       "4  https://a0.muscache.com/im/users/341577/profil...   \n",
       "\n",
       "                                    host_picture_url host_neighbourhood  \\\n",
       "0  https://a0.muscache.com/im/users/151977/profil...   Shibuya District   \n",
       "1  https://a0.muscache.com/im/users/964081/profil...    Sumida District   \n",
       "2  https://a0.muscache.com/im/users/341577/profil...    Nerima District   \n",
       "3  https://a0.muscache.com/im/users/1573631/profi...  Setagaya District   \n",
       "4  https://a0.muscache.com/im/users/341577/profil...    Nerima District   \n",
       "\n",
       "   host_listings_count  host_total_listings_count  \\\n",
       "0                  3.0                        3.0   \n",
       "1                  1.0                        1.0   \n",
       "2                  2.0                        2.0   \n",
       "3                  3.0                        3.0   \n",
       "4                  2.0                        2.0   \n",
       "\n",
       "                                  host_verifications host_has_profile_pic  \\\n",
       "0  ['email', 'phone', 'facebook', 'reviews', 'jum...                    t   \n",
       "1  ['email', 'phone', 'facebook', 'reviews', 'jum...                    t   \n",
       "2  ['email', 'phone', 'reviews', 'jumio', 'govern...                    t   \n",
       "3  ['email', 'phone', 'facebook', 'reviews', 'jum...                    t   \n",
       "4  ['email', 'phone', 'reviews', 'jumio', 'govern...                    t   \n",
       "\n",
       "  host_identity_verified                 street      neighbourhood  \\\n",
       "0                      t  Shibuya, Tokyo, Japan   Shibuya District   \n",
       "1                      t   Sumida, Tokyo, Japan    Sumida District   \n",
       "2                      t   Nerima, Tokyo, Japan    Nerima District   \n",
       "3                      t    Tokyo, Tokyo, Japan  Setagaya District   \n",
       "4                      t   Nerima, Tokyo, Japan    Nerima District   \n",
       "\n",
       "  neighbourhood_cleansed  neighbourhood_group_cleansed     city  state  \\\n",
       "0             Shibuya Ku                           NaN  Shibuya  Tokyo   \n",
       "1              Sumida Ku                           NaN   Sumida  Tokyo   \n",
       "2              Nerima Ku                           NaN   Nerima  Tokyo   \n",
       "3            Setagaya Ku                           NaN    Tokyo  Tokyo   \n",
       "4              Nerima Ku                           NaN   Nerima  Tokyo   \n",
       "\n",
       "    zipcode market  smart_location country_code country  latitude  longitude  \\\n",
       "0  150-0001  Tokyo  Shibuya, Japan           JP   Japan  35.67152  139.71203   \n",
       "1       NaN  Tokyo   Sumida, Japan           JP   Japan  35.71721  139.82596   \n",
       "2       NaN  Tokyo   Nerima, Japan           JP   Japan  35.74267  139.65810   \n",
       "3  156-0042  Tokyo    Tokyo, Japan           JP   Japan  35.66443  139.65707   \n",
       "4       NaN  Tokyo   Nerima, Japan           JP   Japan  35.74264  139.65832   \n",
       "\n",
       "  is_location_exact property_type        room_type  accommodates  bathrooms  \\\n",
       "0                 t     Apartment     Private room             1        1.0   \n",
       "1                 f     Apartment  Entire home/apt             2        1.0   \n",
       "2                 f     Apartment  Entire home/apt             2        1.0   \n",
       "3                 t     Apartment  Entire home/apt             2        1.0   \n",
       "4                 f     Apartment  Entire home/apt             2        1.0   \n",
       "\n",
       "   bedrooms  beds  bed_type  \\\n",
       "0       1.0   1.0  Real Bed   \n",
       "1       1.0   2.0     Futon   \n",
       "2       1.0   1.0  Real Bed   \n",
       "3       0.0   1.0  Real Bed   \n",
       "4       1.0   1.0  Real Bed   \n",
       "\n",
       "                                           amenities  square_feet       price  \\\n",
       "0  {TV,Internet,Wifi,Kitchen,\"Paid parking off pr...          NaN   $4,163.00   \n",
       "1  {TV,Internet,Wifi,\"Air conditioning\",Kitchen,\"...          NaN  $10,993.00   \n",
       "2  {TV,Wifi,\"Air conditioning\",Kitchen,\"Hot tub\",...        220.0   $4,163.00   \n",
       "3  {TV,Internet,Wifi,\"Air conditioning\",Kitchen,\"...        270.0   $7,044.00   \n",
       "4  {TV,Internet,Wifi,\"Air conditioning\",Kitchen,\"...          NaN   $3,949.00   \n",
       "\n",
       "  weekly_price monthly_price security_deposit cleaning_fee  guests_included  \\\n",
       "0          NaN   $110,000.00       $30,000.00    $5,000.00                1   \n",
       "1   $66,000.00   $240,000.00       $40,000.00    $5,000.00                1   \n",
       "2   $28,818.00   $149,426.00       $32,020.00    $5,337.00                1   \n",
       "3   $56,009.00   $198,032.00       $20,000.00    $6,000.00                1   \n",
       "4   $28,818.00   $149,426.00       $32,020.00    $5,337.00                1   \n",
       "\n",
       "  extra_people  minimum_nights  maximum_nights  minimum_minimum_nights  \\\n",
       "0        $0.00              28            1125                      28   \n",
       "1        $0.00               3             365                       3   \n",
       "2    $1,067.00              28             180                       1   \n",
       "3        $0.00              28             720                      28   \n",
       "4    $1,067.00              28             180                       1   \n",
       "\n",
       "   maximum_minimum_nights  minimum_maximum_nights  maximum_maximum_nights  \\\n",
       "0                      28                    1125                    1125   \n",
       "1                       3                     365                     365   \n",
       "2                      30                     180                     180   \n",
       "3                      28                    1125                    1125   \n",
       "4                      28                     180                     180   \n",
       "\n",
       "   minimum_nights_avg_ntm  maximum_nights_avg_ntm calendar_updated  \\\n",
       "0                    28.0                  1125.0    20 months ago   \n",
       "1                     3.0                   365.0     2 months ago   \n",
       "2                    26.5                   180.0     2 months ago   \n",
       "3                    28.0                  1125.0     3 months ago   \n",
       "4                    27.3                   180.0     2 months ago   \n",
       "\n",
       "  has_availability  availability_30  availability_60  availability_90  \\\n",
       "0                t               29               59               89   \n",
       "1                t               28               46               76   \n",
       "2                t               25               28               35   \n",
       "3                t               26               56               86   \n",
       "4                t               30               60               90   \n",
       "\n",
       "   availability_365 calendar_last_scraped  number_of_reviews  \\\n",
       "0                89            2020-06-25                 18   \n",
       "1               300            2020-06-25                165   \n",
       "2               165            2020-06-25                113   \n",
       "3               361            2020-06-25                103   \n",
       "4               353            2020-06-25                104   \n",
       "\n",
       "   number_of_reviews_ltm first_review last_review  review_scores_rating  \\\n",
       "0                      0   2011-12-28  2018-07-28                  94.0   \n",
       "1                      8   2011-09-21  2020-03-04                  95.0   \n",
       "2                      6   2012-06-15  2020-02-17                  95.0   \n",
       "3                      4   2014-03-25  2020-04-16                  95.0   \n",
       "4                      3   2012-10-17  2020-05-12                  96.0   \n",
       "\n",
       "   review_scores_accuracy  review_scores_cleanliness  review_scores_checkin  \\\n",
       "0                     9.0                        9.0                    9.0   \n",
       "1                    10.0                       10.0                   10.0   \n",
       "2                     9.0                       10.0                   10.0   \n",
       "3                    10.0                       10.0                   10.0   \n",
       "4                    10.0                       10.0                   10.0   \n",
       "\n",
       "   review_scores_communication  review_scores_location  review_scores_value  \\\n",
       "0                         10.0                    10.0                  9.0   \n",
       "1                         10.0                     9.0                 10.0   \n",
       "2                          9.0                     9.0                  9.0   \n",
       "3                         10.0                    10.0                 10.0   \n",
       "4                         10.0                     9.0                 10.0   \n",
       "\n",
       "  requires_license                                            license  \\\n",
       "0                t  Other reasons | \\nå¼Šç¤¾ã¯ä¸å‹•ç”£äº‹æ¥­è€…ã§ã‚ã‚Šè³ƒè²¸ä½å®…ç®¡ç†äº‹æ¥­è€…ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚...   \n",
       "1                t                                         M130003350   \n",
       "2                t  Other reasons | 1ã‹æœˆä»¥ä¸Šã®è³ƒè²¸å€Ÿå¥‘ç´„ã®ã¿å¯¾å¿œã¨ã™ã‚‹ã€‚ã‚²ã‚¹ãƒˆã«ã¯è³ƒè²¸å¥‘ç´„ã®ç½²...   \n",
       "3                t  Other reasons | We called Setagaya ku hokenjo ...   \n",
       "4                t  Other reasons | 1ã‹æœˆä»¥ä¸Šã®è³ƒè²¸å€Ÿå¥‘ç´„ã®ã¿å¯¾å¿œã¨ã™ã‚‹ã€‚ã‚²ã‚¹ãƒˆã«ã¯è³ƒè²¸å¥‘ç´„ã®ç½²...   \n",
       "\n",
       "   jurisdiction_names instant_bookable is_business_travel_ready  \\\n",
       "0                 NaN                f                        f   \n",
       "1                 NaN                f                        f   \n",
       "2                 NaN                f                        f   \n",
       "3                 NaN                t                        f   \n",
       "4                 NaN                f                        f   \n",
       "\n",
       "           cancellation_policy require_guest_profile_picture  \\\n",
       "0  strict_14_with_grace_period                             f   \n",
       "1                     moderate                             f   \n",
       "2  strict_14_with_grace_period                             f   \n",
       "3                     moderate                             f   \n",
       "4  strict_14_with_grace_period                             f   \n",
       "\n",
       "  require_guest_phone_verification  calculated_host_listings_count  \\\n",
       "0                                f                               3   \n",
       "1                                f                               1   \n",
       "2                                f                               2   \n",
       "3                                f                               3   \n",
       "4                                f                               2   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                            2   \n",
       "1                                            1   \n",
       "2                                            2   \n",
       "3                                            3   \n",
       "4                                            2   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                             1   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \n",
       "0                                            0               0.17  \n",
       "1                                            0               1.55  \n",
       "2                                            0               1.16  \n",
       "3                                            0               1.35  \n",
       "4                                            0               1.11  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a ton of variables available so things will get very fun in the next part when we get to data cleaning.\n",
    "\n",
    "Let's have a quick look at how many files we downloaded in total. To do this we will use the glob module, which is part of the starndard library of Python. Glob allows us use pattern matching to find files in one or many nested directories in our computer. For example, in the file path `my_data/*.csv`, the wildcard `*` will help us select all files, regardless of their names, that end up with `.csv`. In contrast, the `os.path.join()` below helps us connect different directories together regardless of the operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " ['../data\\\\cape-town_data\\\\raw_data\\\\cape-town_3.csv.gz',\n",
       "  '../data\\\\japan_data\\\\raw_data\\\\japan_0.csv.gz',\n",
       "  '../data\\\\japan_data\\\\raw_data\\\\japan_1.csv.gz',\n",
       "  '../data\\\\japan_data\\\\raw_data\\\\japan_2.csv.gz',\n",
       "  '../data\\\\japan_data\\\\raw_data\\\\japan_3.csv.gz'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(os.path.join(path, '*_data', 'raw_data', '*.csv.gz'))\n",
    "len(files), files[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of all of our files, we will create a function to help us decompress the files and save them as comma separated value fules (i.e. `CSV`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_files(data, path_out, new_dir, country_city, nums):\n",
    "    \"\"\"\n",
    "    data: the compressed file\n",
    "    path_out: the directory all of our data for this project\n",
    "    new_dir: new directory for the uncompressed files\n",
    "    country_city: name of the country\n",
    "    nums: number of files available\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data, compression='gzip',  low_memory=False, encoding='utf-8')\n",
    "    \n",
    "    df.to_csv(os.path.join(check_or_add(path_out, country_city + '_data', new_dir), \n",
    "                                        f'{country_city}_{nums}.csv'), index=False, encoding='utf-8')\n",
    "    \n",
    "    print(f\"Done Reading and Saving file {nums}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to introduce Dask to the session. In essence:\n",
    "\n",
    "> \"Dask provides advanced parallelism for analytics, enabling performance at scale for the tools you love\" ~ [dask.org](https://dask.org/)\n",
    "\n",
    "One of the best features of Dask is that it allows you to scale regular Python code for data analysis to either fully use all of the resources in your machine or to scale your computations to a cluster of machines. Dask does this by integrating itself with some of the most well known tools in the data analytics domain such as pandas, NumPy, SciKit-Learn, its own dask bags which are great for processing large unstructured files, and many more. In addition, it allows you to create your own parallelised workflow with a useful function called `delayed()` that lazily starts building up a paralellised computational graph.\n",
    "\n",
    "The `delayed` object is the dask functionality we will be taking advantage of to process all of our compressed files in parallel. \n",
    "\n",
    "Let's go over a quick example inspired from one in Dask's own tutorials. Here, we will create a sleepy pemdas function. You might remember this order of operations from your high school days, where your math teacher would tell you that parentheses always come firt, followed by the exponents, then the multiplication, the division, the addition and the subtraction when doing operations. We will follow this pemdas order of operations with the pandas Series of a toy dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's import the delayed function from dask\n",
    "from dask import delayed\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B   C\n",
       "0  1  5   9\n",
       "1  2  6  10\n",
       "2  3  7  11\n",
       "3  4  8  12"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a toy dataframe for our computation\n",
    "toy_df = pd.DataFrame({\"A\": [1, 2, 3, 4],\n",
    "                       \"B\": [5, 6, 7, 8],\n",
    "                       \"C\": [9, 10, 11, 12]})\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have our functions. We are skipping the parentheses as we will test them all in different calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponents(a):\n",
    "    sleep(1)\n",
    "    return a ** 2\n",
    "\n",
    "def mult(b, c, d):\n",
    "    sleep(1)\n",
    "    return b * c * d\n",
    "\n",
    "def divide(d, e, f):\n",
    "    sleep(1)\n",
    "    return (d / e) / f\n",
    "\n",
    "def addition(f, g, h):\n",
    "    sleep(1)\n",
    "    return f + g + h\n",
    "\n",
    "def subtraction(h, i, j):\n",
    "    sleep(1)\n",
    "    return h - i - j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first run these functions without using dask delayed and time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "Name: A, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1917.999506\n",
       "1     14259.998889\n",
       "2     53181.998482\n",
       "3    147231.998264\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ex = exponents(toy_df['A'])\n",
    "ex1 = exponents(toy_df['B'])\n",
    "ex2 = exponents(toy_df['C'])\n",
    "\n",
    "\n",
    "mu = mult(ex, ex1, ex2)\n",
    "\n",
    "di = divide(ex, ex1, ex2)\n",
    "\n",
    "ad = addition(ex, ex1, ex2)\n",
    "\n",
    "result = subtraction(mu, di, ad)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this operation takes about 7 seconds because each needs to sleep for one before advancing. Now, let compute and visualise the computation graph we are creating with dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 996 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ex = delayed(exponents)(toy_df['A'])\n",
    "ex1 = delayed(exponents)(toy_df['B'])\n",
    "ex2 = delayed(exponents)(toy_df['C'])\n",
    "\n",
    "mu = delayed(mult)(ex, ex1, ex2)\n",
    "di = delayed(divide)(ex, ex1, ex2)\n",
    "ad = delayed(addition)(ex, ex1, ex2)\n",
    "result = delayed(subtraction)(mu, di, ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('subtraction-1b59f150-b2c6-45c8-b285-e5e2bacafd32')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      1917.999506\n",
       "1     14259.998889\n",
       "2     53181.998482\n",
       "3    147231.998264\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate what just happened, dask will create a directed acyclic graph for us that shows us the order in which the computations took place. In order to use this functionality, we need to have installed the `python-graphviz` module and the actual [graphviz](https://www.graphviz.org/) tool.\n",
    "\n",
    "First download the first command or go to graphviz website and use the appropriate download option for your operating system. Then procede to the second command.\n",
    "\n",
    "```sh\n",
    "\n",
    "# first command\n",
    "conda install -c conda-forge graphviz -y\n",
    "\n",
    "# second command\n",
    "pip install graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\rick\\anaconda3\\lib\\site-packages (0.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_startupinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-dc769738af30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(self, filename, format, optimize_graph, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morg\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlatest\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         return visualize(\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown value color=%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdot_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\dot.py\u001b[0m in \u001b[0;36mdot_graph\u001b[1;34m(dsk, filename, format, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \"\"\"\n\u001b[0;32m    270\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraphviz_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dask\\dot.py\u001b[0m in \u001b[0;36mgraphviz_to_file\u001b[1;34m(g, filename, format)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         out = backend.pipe(self._engine, format, data,\n\u001b[0m\u001b[0;32m    137\u001b[0m                            \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                            quiet=quiet)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(engine, format, data, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \"\"\"\n\u001b[0;32m    243\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(cmd, input, capture_output, check, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tpng'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "result.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "1. Create a pandas dataframe with fake data.\n",
    "2. Create 2 functions that perform a computation on a different pandas Series of your dataframe each. Make your functions so that they sleep for 1 second.\n",
    "3. Create 1 function that takes the outputof the previous two and return either an array or a single number. Make your functions so that they sleep for 1 second.\n",
    "4. Evaluate the implementation of your functions **without** dask.delayed. Time it with `%%time` at the top of your cell.\n",
    "5. Evaluate the implementation of your functions **using** dask.delayed. Time it with `%%time` at the top of your cell.\n",
    "6. Compare both functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your 3 functions go here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First implementation goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delay your functions here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test your delayed functions here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply our `get_csv_files()` function using dask delayed to process the decompression of the files in a much faster manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "for num, file in enumerate(files):\n",
    "    \n",
    "    if my_country in file:\n",
    "        result = dask.delayed(get_csv_files)(data=file, path_out=path, new_dir='csv_files', country_city=my_country, nums=num)\n",
    "        results.append(result)\n",
    "        \n",
    "    elif my_country2 in file:\n",
    "        result = dask.delayed(get_csv_files)(data=file, path_out=path, new_dir='csv_files', country_city=my_country2, nums=num)\n",
    "        results.append(result)\n",
    "        \n",
    "    elif my_city in file:\n",
    "        result = dask.delayed(get_csv_files)(data=file, path_out=path, new_dir='csv_files', country_city=my_city, nums=num)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Delayed('get_csv_files-b6d0d06d-0dd5-49a2-90f3-c242f80d74f1'),\n",
       " Delayed('get_csv_files-6190f50e-345f-4c0c-8326-d83def0ebbc3'),\n",
       " Delayed('get_csv_files-3db6ad0b-109f-4107-a9e6-1e7c41fbc224'),\n",
       " Delayed('get_csv_files-5717d4f2-ddaa-4f28-b6f4-1b3a14c18c2d'),\n",
       " Delayed('get_csv_files-9ab5031b-4d5a-4e54-acf1-60689cd9dd70')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the delayed objects above. Since they have all been accumulated inside a list, we will use a list comprehentions to loop over them while computing the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Reading and Saving file 0!\n",
      "Done Reading and Saving file 1!\n",
      "Done Reading and Saving file 2!\n",
      "Done Reading and Saving file 3!\n",
      "Done Reading and Saving file 4!\n",
      "Done Reading and Saving file 5!\n",
      "Done Reading and Saving file 6!\n",
      "Done Reading and Saving file 7!\n",
      "Done Reading and Saving file 8!\n",
      "Done Reading and Saving file 9!\n",
      "Done Reading and Saving file 10!\n",
      "Done Reading and Saving file 11!\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results_done = [result.compute() for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that you have the correct amount of decompressed files with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob(os.path.join(path, '*_data', 'csv_files', '*.csv'))\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome Work! Now to Clean and Reshape our Data!\n",
    "\n",
    "![Cleaning](https://media.giphy.com/media/RjpE964WUAE5a/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary\n",
    "\n",
    "In this notebook we learned:\n",
    "\n",
    "1. How to think about the data analytics cycle.\n",
    "2. How to form a project/idea/task.\n",
    "3. To find the data we need and work around the inconsistencies that might arise in the process.\n",
    "4. How to make directories/folders work with us.\n",
    "5. How to manipulate 1-dimensional arrays using pandas Series, and 2-dimensional data structures using pandas dataframe.\n",
    "6. To delay, and lazily compute operations using dask."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
